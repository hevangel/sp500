pipeline {
    agent {
        node {
            label 'linux'
            customWorkspace "${env.HOME}/workspace/stock_scrapper"
        }
    }
    triggers {
        cron('H 0 * * 6')
    }
    stages {
        stage('fetch') {
            steps {
                dir('../stock_data') {
                    git url: 'git@github.com:hevangel/stock_data.git', credentialsId: 'git-hevangel'
                }
            }
        }
        stage('scrap') {
            steps {
                sh 'pip install --upgrade pip'
                sh 'python3 -m venv --system-site-packages venv'
                withPythonEnv("${WORKSPACE}/venv/") {
                    sh 'pip3 install -r requirements.txt --upgrade'
                    sh 'python scrap_etf_info.py'
                }
            }
        }
        stage('deploy') {
            steps {
                dir('../stock_data') {
                    sh 'git add data_tickers/*.csv'
                    sh 'git commit --allow-empty -a -m "weekly update"'
                    sshagent (['git-hevangel']) {
                        sh 'git push origin HEAD:master'
                    }
                }
            }
        }
    }
    post {
        always {
            echo 'This will always run'
        }
        success {
            echo 'This will run only if successful'
        }
        failure {
            echo 'This will run only if failed'
        }
        unstable {
            echo 'This will run only if the run was marked as unstable'
        }
        changed {
            echo 'This will run only if the state of the Pipeline has changed'
            echo 'For example, if the Pipeline was previously failing but is now successful'
        }
    }
}